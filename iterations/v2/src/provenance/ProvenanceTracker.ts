/**
 * Provenance Tracker
 *
 * Tracks AI attribution, maintains provenance chains, and integrates with CAWS
 * provenance tracking for compliance and audit purposes.
 *
 * @author @darianrosebrook
 */

import * as crypto from "crypto";
import { EventEmitter } from "events";
import * as fs from "fs/promises";
import * as path from "path";
import type {
  AIAttribution,
  AIAttributionStats,
  AIToolDetectionPatterns,
  AIToolType,
  AttributionConfidence,
  CAWSProvenanceIntegration,
  GitCommitInfo,
  GitIntegration,
  ProvenanceChain,
  ProvenanceEntry,
  ProvenanceEntryType,
  ProvenanceReport,
  ProvenanceStorage,
  ProvenanceTrackerCapabilities,
  ProvenanceTrackerConfig,
  ProvenanceTrackerEvents,
} from "./types/provenance-types.js";

/**
 * Main ProvenanceTracker class
 *
 * Tracks AI tool usage, maintains provenance chains, and integrates with CAWS.
 */
export class ProvenanceTracker extends EventEmitter {
  private config: ProvenanceTrackerConfig;
  private storage: ProvenanceStorage;
  private gitIntegration?: GitIntegration;
  private cawsIntegration: CAWSProvenanceIntegration;
  private aiDetectionPatterns: AIToolDetectionPatterns;
  private integrityCheckInterval?: ReturnType<typeof setInterval>;

  /** Default AI tool detection patterns */
  private static readonly DEFAULT_AI_PATTERNS: AIToolDetectionPatterns = {
    filePatterns: [
      "**/*.{ts,tsx,js,jsx,py,java,cpp,c,h,hpp,rs,go}",
      "**/*.md",
      "**/*.yaml",
      "**/*.yml",
    ],
    contentPatterns: [
      {
        toolType: "cursor-composer",
        patterns: [
          /\/\/ Generated by Cursor Composer/i,
          /\/\* Generated by Cursor Composer \*\//i,
          /# Generated by Cursor Composer/i,
        ],
        confidence: "high",
      },
      {
        toolType: "cursor-tab-completion",
        patterns: [
          /\/\/ Cursor tab completion/i,
          /\/\* Cursor tab completion \*\//i,
        ],
        confidence: "medium",
      },
      {
        toolType: "github-copilot",
        patterns: [
          /\/\/ GitHub Copilot/i,
          /\/\* GitHub Copilot \*\//i,
          /# GitHub Copilot/i,
        ],
        confidence: "high",
      },
      {
        toolType: "claude",
        patterns: [/\/\/ Claude AI/i, /\/\* Claude AI \*\//i, /# Claude AI/i],
        confidence: "high",
      },
      {
        toolType: "gpt-4",
        patterns: [/\/\/ GPT-4/i, /\/\* GPT-4 \*\//i, /# GPT-4/i],
        confidence: "high",
      },
    ],
    gitPatterns: [
      {
        toolType: "cursor-composer",
        commitMessagePatterns: [/composer/i, /cursor.*generate/i],
        authorPatterns: [/cursor/i, /composer/i],
        confidence: "medium",
      },
      {
        toolType: "github-copilot",
        commitMessagePatterns: [/copilot/i, /ai.*assist/i],
        authorPatterns: [/copilot/i],
        confidence: "medium",
      },
    ],
  };

  constructor(config: ProvenanceTrackerConfig) {
    super();
    this.config = config;
    this.storage = this.createStorage();
    this.cawsIntegration = {
      status: "disconnected",
    };
    this.aiDetectionPatterns = ProvenanceTracker.DEFAULT_AI_PATTERNS;

    if (config.cawsIntegration?.enabled) {
      this.initializeCAWSIntegration();
    }

    if (config.verification?.enabled) {
      this.startIntegrityChecks();
    }
  }

  /**
   * Get tracker capabilities
   */
  getCapabilities(): ProvenanceTrackerCapabilities {
    return {
      trackAIAttribution: this.config.enableAIAttribution ?? true,
      trackHumanContributions: true,
      integrateWithCAWS: this.config.cawsIntegration?.enabled ?? false,
      verifyIntegrity: this.config.verification?.enabled ?? false,
      generateReports: true,
      analyzePatterns: true,
    };
  }

  /**
   * Record a provenance entry
   */
  async recordEntry(
    type: ProvenanceEntryType,
    specId: string,
    actor: ProvenanceEntry["actor"],
    action: ProvenanceEntry["action"],
    options: {
      commitHash?: string;
      affectedFiles?: ProvenanceEntry["affectedFiles"];
      qualityMetrics?: ProvenanceEntry["qualityMetrics"];
      aiAttributions?: AIAttribution[];
      parentEntries?: string[];
      metadata?: Record<string, unknown>;
    } = {}
  ): Promise<ProvenanceEntry> {
    const entry: ProvenanceEntry = {
      id: this.generateId(),
      type,
      specId,
      timestamp: new Date().toISOString(),
      actor,
      action,
      ...options,
    };

    // Auto-detect AI attributions if enabled
    if (this.config.enableAIAttribution && !options.aiAttributions) {
      entry.aiAttributions = await this.detectAIAttributions(entry);

      // Store detected attributions separately for statistics
      if (entry.aiAttributions) {
        for (const attribution of entry.aiAttributions) {
          await this.storage.storeAttribution(attribution);
        }
      }
    }

    await this.storage.storeEntry(entry);

    // Update provenance chain
    await this.updateProvenanceChain(entry);

    this.emit("entry:added", entry);

    return entry;
  }

  /**
   * Record AI attribution
   */
  async recordAIAttribution(
    toolType: AIToolType,
    toolVersion?: string,
    codeRegions?: AIAttribution["codeRegions"],
    confidence: AttributionConfidence = "medium",
    metadata?: Record<string, unknown>
  ): Promise<AIAttribution> {
    const attribution: AIAttribution = {
      id: this.generateId(),
      toolType,
      toolVersion,
      confidence,
      timestamp: new Date().toISOString(),
      codeRegions,
      metadata,
    };

    await this.storage.storeAttribution(attribution);

    this.emit("attribution:recorded", attribution);

    return attribution;
  }

  /**
   * Get provenance chain for a spec
   */
  async getProvenanceChain(specId: string): Promise<ProvenanceChain | null> {
    return this.storage.getProvenanceChain(specId);
  }

  /**
   * Get AI attribution statistics
   */
  async getAIAttributionStats(
    startDate?: string,
    endDate?: string
  ): Promise<AIAttributionStats> {
    const start =
      startDate ||
      new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString();
    const end = endDate || new Date().toISOString();

    const attributions = await this.storage.getAttributions(start, end);

    // Calculate statistics
    const byToolType = attributions.reduce((acc, attr) => {
      acc[attr.toolType] = (acc[attr.toolType] || 0) + 1;
      return acc;
    }, {} as Record<AIToolType, number>);

    const byConfidence = attributions.reduce(
      (acc, attr) => {
        acc[attr.confidence] = (acc[attr.confidence] || 0) + 1;
        return acc;
      },
      { low: 0, medium: 0, high: 0, certain: 0 }
    );

    const topTools = Object.entries(byToolType)
      .map(([toolType, count]) => ({
        toolType: toolType as AIToolType,
        count,
        percentage: (count / attributions.length) * 100,
      }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 5);

    // Calculate trends (simplified - would need more complex date bucketing)
    const trends = {
      daily: [] as Array<{ date: string; count: number }>,
      weekly: [] as Array<{ week: string; count: number }>,
      monthly: [] as Array<{ month: string; count: number }>,
    };

    // Calculate average confidence
    const confidenceValues = { low: 1, medium: 2, high: 3, certain: 4 };
    const averageConfidence =
      attributions.reduce(
        (sum, attr) => sum + confidenceValues[attr.confidence],
        0
      ) / attributions.length;

    // Calculate code coverage (simplified)
    const attributedLines = attributions.reduce(
      (sum, attr) => sum + (attr.codeRegions?.length || 0),
      0
    );

    return {
      total: attributions.length,
      byToolType,
      byConfidence,
      topTools,
      trends,
      averageConfidence,
      codeCoverage: {
        attributedLines,
        totalLines: 10000, // Would need actual codebase analysis
        percentage: (attributedLines / 10000) * 100,
      },
    };
  }

  /**
   * Generate provenance report
   */
  async generateReport(
    specId: string,
    type: "summary" | "detailed" | "compliance" | "audit" = "summary",
    period?: { start: string; end: string }
  ): Promise<ProvenanceReport> {
    const chain = await this.getProvenanceChain(specId);
    if (!chain) {
      throw new Error(`No provenance chain found for spec ${specId}`);
    }

    const defaultPeriod = {
      start: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString(),
      end: new Date().toISOString(),
    };

    const reportPeriod = period || defaultPeriod;
    const aiStats = await this.getAIAttributionStats(
      reportPeriod.start,
      reportPeriod.end
    );

    // Generate quality metrics trends
    const qualityMetrics = await this.generateQualityMetricsTrends(
      chain,
      reportPeriod
    );

    // Ensure chain has statistics before assessing risks
    if (!chain.statistics) {
      chain.statistics = this.calculateChainStatistics(chain);
    }

    // Assess risks
    const riskAssessment = this.assessProvenanceRisks(chain, aiStats);

    // Check compliance
    const compliance = await this.checkCompliance(chain);

    const report: ProvenanceReport = {
      id: this.generateId(),
      specId: chain.id,
      type,
      period: reportPeriod,
      spec: chain.spec,
      aiStats,
      provenanceChain: chain,
      cawsIntegration: this.cawsIntegration,
      qualityMetrics,
      riskAssessment,
      compliance,
      generatedAt: new Date().toISOString(),
      hash: this.calculateReportHash(chain, aiStats),
    };

    this.emit("report:generated", report);

    return report;
  }

  /**
   * Sync with CAWS provenance system
   */
  async syncWithCAWS(): Promise<void> {
    if (!this.config.cawsIntegration?.enabled) {
      return;
    }

    try {
      // This would integrate with actual CAWS CLI
      // For now, simulate the sync
      this.cawsIntegration = {
        status: "connected",
        lastSync: new Date().toISOString(),
        syncStats: {
          entriesSynced: 10,
          entriesFailed: 0,
          lastSyncDuration: 500,
        },
      };

      this.emit("caws:synced", this.cawsIntegration);
    } catch (error) {
      this.cawsIntegration = {
        status: "error",
        error: {
          message: error instanceof Error ? error.message : "Unknown error",
          timestamp: new Date().toISOString(),
        },
      };

      this.emit("tracker:error", error as Error);
    }
  }

  /**
   * Verify provenance chain integrity
   */
  async verifyIntegrity(
    specId: string
  ): Promise<{ verified: boolean; issues?: string[] }> {
    const chain = await this.getProvenanceChain(specId);
    if (!chain) {
      return { verified: false, issues: ["No provenance chain found"] };
    }

    const issues: string[] = [];

    // Ensure integrity property exists
    if (!chain.integrity) {
      chain.integrity = {
        verified: true,
        lastVerified: new Date().toISOString(),
        hash: "",
      };
    }

    // Verify chain hash
    const currentHash = this.calculateChainHash(chain.entries);
    if (chain.integrity.hash && currentHash !== chain.integrity.hash) {
      issues.push("Chain hash mismatch - integrity compromised");
    } else if (!chain.integrity.hash) {
      // If no hash is stored, update it
      chain.integrity.hash = currentHash;
      chain.integrity.lastVerified = new Date().toISOString();
    }

    // Verify entry timestamps are sequential
    const sortedEntries = [...chain.entries].sort(
      (a, b) =>
        new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
    );

    for (let i = 1; i < sortedEntries.length; i++) {
      const prev = sortedEntries[i - 1];
      const current = sortedEntries[i];

      if (new Date(current.timestamp) < new Date(prev.timestamp)) {
        issues.push(`Entry ${current.id} has timestamp before previous entry`);
      }
    }

    // Verify parent-child relationships
    for (const entry of chain.entries) {
      if (entry.parentEntries) {
        for (const parentId of entry.parentEntries) {
          const parent = chain.entries.find((e) => e.id === parentId);
          if (!parent) {
            issues.push(
              `Entry ${entry.id} references non-existent parent ${parentId}`
            );
          }
        }
      }
    }

    const verified = issues.length === 0;

    this.emit("integrity:checked", chain, verified);

    return { verified, issues: verified ? undefined : issues };
  }

  /**
   * Analyze contribution patterns
   */
  async analyzePatterns(specId: string): Promise<{
    aiVsHumanBalance: number;
    productivityTrends: Array<{
      date: string;
      aiContribution: number;
      humanContribution: number;
    }>;
    collaborationPatterns: Record<string, any>;
    qualityCorrelation: {
      aiUsage: number;
      qualityScore: number;
      correlation: number;
    };
  }> {
    const chain = await this.getProvenanceChain(specId);
    if (!chain || chain.entries.length === 0) {
      // Return empty analysis for empty or non-existent chains
      return {
        aiVsHumanBalance: 0,
        productivityTrends: [],
        collaborationPatterns: {},
        qualityCorrelation: {
          aiUsage: 0,
          qualityScore: 0,
          correlation: 0,
        },
      };
    }

    const aiEntries = chain.entries.filter(
      (e) => e.aiAttributions && e.aiAttributions.length > 0
    );
    const humanEntries = chain.entries.filter((e) => e.actor.type === "human");

    const aiVsHumanBalance =
      aiEntries.length / Math.max(humanEntries.length, 1);

    // Simplified trend analysis
    const productivityTrends: Array<{
      date: string;
      aiContribution: number;
      humanContribution: number;
    }> = [];

    // Simplified collaboration patterns
    const collaborationPatterns = {
      aiToolsUsed: [
        ...new Set(
          aiEntries.flatMap(
            (e) => e.aiAttributions?.map((a) => a.toolType) || []
          )
        ),
      ],
      humanReviewFrequency:
        humanEntries.filter((e) => e.action.type === "reviewed").length /
        humanEntries.length,
    };

    // Ensure chain has statistics before analyzing patterns
    if (!chain.statistics) {
      chain.statistics = this.calculateChainStatistics(chain);
    }

    // Simplified quality correlation
    const qualityCorrelation = {
      aiUsage: aiVsHumanBalance,
      qualityScore:
        chain.statistics.qualityTrends.testCoverage.slice(-1)[0]?.value || 0,
      correlation: 0.5, // Would need statistical analysis
    };

    return {
      aiVsHumanBalance,
      productivityTrends,
      collaborationPatterns,
      qualityCorrelation,
    };
  }

  /**
   * Clean up old data based on retention policy
   */
  async cleanup(
    retentionDays: number = 90
  ): Promise<{ entriesRemoved: number; attributionsRemoved: number }> {
    try {
      const result = await this.storage.cleanup(retentionDays);
      this.emit("tracker:cleanup", result);
      return result;
    } catch (error) {
      this.emit("tracker:error", error as Error);
      throw error;
    }
  }

  /**
   * Stop the tracker and clean up resources
   */
  stop(): void {
    if (this.integrityCheckInterval) {
      clearInterval(this.integrityCheckInterval);
    }
  }

  // Private methods

  private createStorage(): ProvenanceStorage {
    // For now, use file-based storage
    // In production, this could be database-backed
    return new FileBasedStorage(
      this.config.storage?.path ||
        path.join(this.config.projectRoot, ".caws", "provenance")
    );
  }

  private async initializeCAWSIntegration(): Promise<void> {
    try {
      await this.syncWithCAWS();
    } catch (error) {
      this.emit("tracker:error", error as Error);
    }
  }

  private startIntegrityChecks(): void {
    const interval = this.config.verification?.intervalMs || 3600000; // 1 hour default

    this.integrityCheckInterval = setInterval(async () => {
      try {
        await this.verifyIntegrity(this.config.spec.id);
      } catch (error) {
        this.emit("tracker:error", error as Error);
      }
    }, interval);
  }

  private async detectAIAttributions(
    entry: ProvenanceEntry
  ): Promise<AIAttribution[]> {
    const attributions: AIAttribution[] = [];

    // Check affected files for AI patterns
    if (entry.affectedFiles) {
      for (const file of entry.affectedFiles) {
        const fileAttributions = await this.detectAIInFile(file.path);
        attributions.push(...fileAttributions);
      }
    }

    // Check commit message for AI patterns
    if (entry.commitHash && this.gitIntegration) {
      const commit = await this.gitIntegration.getCommitDetails(
        entry.commitHash
      );
      if (commit) {
        const commitAttributions = this.detectAIInCommit(commit);
        attributions.push(...commitAttributions);
      }
    }

    return attributions;
  }

  private async detectAIInFile(filePath: string): Promise<AIAttribution[]> {
    const attributions: AIAttribution[] = [];

    try {
      // Resolve relative paths against project root
      const fullPath = path.isAbsolute(filePath)
        ? filePath
        : path.join(this.config.projectRoot, filePath);
      const content = await fs.readFile(fullPath, "utf-8");

      for (const pattern of this.aiDetectionPatterns.contentPatterns) {
        for (const regex of pattern.patterns) {
          const matches = content.match(regex);
          if (matches) {
            attributions.push({
              id: this.generateId(),
              toolType: pattern.toolType,
              confidence: pattern.confidence,
              timestamp: new Date().toISOString(),
              codeRegions: [
                {
                  file: filePath,
                  startLine: 1,
                  endLine: content.split("\n").length,
                },
              ],
            });
            break; // Only add one attribution per tool type per file
          }
        }
      }
    } catch (error) {
      // Ignore file read errors
    }

    return attributions;
  }

  private detectAIInCommit(commit: GitCommitInfo): AIAttribution[] {
    const attributions: AIAttribution[] = [];

    for (const pattern of this.aiDetectionPatterns.gitPatterns) {
      let detected = false;

      // Check commit message
      for (const regex of pattern.commitMessagePatterns) {
        if (regex.test(commit.message)) {
          detected = true;
          break;
        }
      }

      // Check author
      if (!detected) {
        for (const regex of pattern.authorPatterns) {
          if (
            regex.test(commit.author.name) ||
            regex.test(commit.author.email)
          ) {
            detected = true;
            break;
          }
        }
      }

      if (detected) {
        attributions.push({
          id: this.generateId(),
          toolType: pattern.toolType,
          confidence: pattern.confidence,
          timestamp: commit.timestamp,
        });
      }
    }

    return attributions;
  }

  private async updateProvenanceChain(entry: ProvenanceEntry): Promise<void> {
    const chain =
      (await this.storage.getProvenanceChain(entry.specId)) ||
      this.createEmptyChain(entry.specId);

    // Ensure integrity property exists (for chains loaded from storage)
    if (!chain.integrity) {
      chain.integrity = {
        verified: true,
        lastVerified: new Date().toISOString(),
        hash: "",
      };
    }

    // Ensure statistics property exists (for chains loaded from storage)
    if (!chain.statistics) {
      chain.statistics = this.calculateChainStatistics(chain);
    }

    chain.entries.push(entry);
    chain.statistics = this.calculateChainStatistics(chain);
    chain.integrity.hash = this.calculateChainHash(chain.entries);
    chain.integrity.lastVerified = new Date().toISOString();

    // Store the updated chain
    await this.storage.storeProvenanceChain(chain);
    this.emit("chain:updated", chain);
  }

  private createEmptyChain(specId: string): ProvenanceChain {
    return {
      id: specId,
      spec: this.config.spec,
      entries: [],
      statistics: {
        totalEntries: 0,
        aiAssistedEntries: 0,
        humanEntries: 0,
        aiToolsUsed: [],
        timeSpan: {
          start: new Date().toISOString(),
          end: new Date().toISOString(),
          durationMs: 0,
        },
        qualityTrends: {
          testCoverage: [],
          lintErrors: [],
          budgetUsage: [],
        },
      },
      integrity: {
        verified: true,
        lastVerified: new Date().toISOString(),
        hash: "",
      },
    };
  }

  private calculateChainStatistics(
    chain: ProvenanceChain
  ): ProvenanceChain["statistics"] {
    const aiAssistedEntries = chain.entries.filter(
      (e) => e.aiAttributions && e.aiAttributions.length > 0
    ).length;

    const humanEntries = chain.entries.filter(
      (e) => e.actor.type === "human"
    ).length;

    const aiToolsUsed = [
      ...new Set(
        chain.entries.flatMap(
          (e) => e.aiAttributions?.map((a) => a.toolType) || []
        )
      ),
    ];

    const timestamps = chain.entries.map((e) =>
      new Date(e.timestamp).getTime()
    );
    const now = Date.now();
    const start = timestamps.length > 0 ? Math.min(...timestamps) : now;
    const end = timestamps.length > 0 ? Math.max(...timestamps) : now;

    return {
      totalEntries: chain.entries.length,
      aiAssistedEntries,
      humanEntries,
      aiToolsUsed,
      timeSpan: {
        start: new Date(start).toISOString(),
        end: new Date(end).toISOString(),
        durationMs: end - start,
      },
      qualityTrends: {
        testCoverage: [],
        lintErrors: [],
        budgetUsage: [],
      },
    };
  }

  private calculateChainHash(entries: ProvenanceEntry[]): string {
    const data = JSON.stringify(
      entries.map((e) => ({
        id: e.id,
        timestamp: e.timestamp,
        actor: e.actor,
        action: e.action,
      }))
    );

    return crypto.createHash("sha256").update(data).digest("hex");
  }

  private calculateReportHash(
    chain: ProvenanceChain,
    aiStats: AIAttributionStats
  ): string {
    const data = JSON.stringify({
      chainId: chain.id,
      entryCount: chain.entries.length,
      aiStatsTotal: aiStats.total,
      timestamp: new Date().toISOString(),
    });

    return crypto.createHash("sha256").update(data).digest("hex");
  }

  private async generateQualityMetricsTrends(
    _chain: ProvenanceChain,
    _period: { start: string; end: string }
  ): Promise<ProvenanceReport["qualityMetrics"]> {
    // This would analyze the quality metrics from provenance entries
    // For now, return empty trends
    return {
      testCoverage: [],
      lintErrors: [],
      typeErrors: [],
      budgetUsage: [],
    };
  }

  private assessProvenanceRisks(
    chain: ProvenanceChain,
    aiStats: AIAttributionStats
  ): ProvenanceReport["riskAssessment"] {
    const riskFactors: string[] = [];
    const recommendations: string[] = [];

    // Assess AI over-reliance
    const aiRatio =
      chain.statistics.aiAssistedEntries /
      Math.max(chain.statistics.totalEntries, 1);
    if (aiRatio > 0.8) {
      riskFactors.push(
        "High AI contribution ratio may indicate insufficient human oversight"
      );
      recommendations.push(
        "Increase human review frequency for AI-generated code"
      );
    }

    // Assess tool diversity
    if (chain.statistics.aiToolsUsed.length === 1) {
      riskFactors.push("Single AI tool usage reduces diversity and resilience");
      recommendations.push(
        "Consider using multiple AI tools for cross-validation"
      );
    }

    // Assess attribution confidence
    if (aiStats.averageConfidence < 2) {
      riskFactors.push("Low confidence in AI attribution detection");
      recommendations.push(
        "Improve AI detection patterns and manual verification"
      );
    }

    const overallRisk =
      riskFactors.length > 2
        ? "high"
        : riskFactors.length > 0
        ? "medium"
        : "low";

    return {
      overallRisk: overallRisk as any,
      riskFactors,
      recommendations,
    };
  }

  private async checkCompliance(
    chain: ProvenanceChain
  ): Promise<ProvenanceReport["compliance"]> {
    const issues: string[] = [];
    const recommendations: string[] = [];

    // Check CAWS integration
    if (!this.cawsIntegration || this.cawsIntegration.status !== "connected") {
      issues.push("CAWS provenance integration not active");
      recommendations.push("Enable and verify CAWS integration");
    }

    // Check provenance completeness
    const requiredEntryTypes: ProvenanceEntryType[] = [
      "commit",
      "validation",
      "quality_gate",
    ];
    for (const type of requiredEntryTypes) {
      const entriesOfType = chain.entries.filter((e) => e.type === type);
      if (entriesOfType.length === 0) {
        issues.push(`Missing required provenance entries of type: ${type}`);
        recommendations.push(
          `Ensure ${type} entries are recorded in provenance chain`
        );
      }
    }

    // Check integrity
    const integrity = await this.verifyIntegrity(chain.id);
    if (!integrity.verified) {
      issues.push("Provenance chain integrity verification failed");
      recommendations.push(
        "Review and repair provenance chain integrity issues"
      );
    }

    return {
      cawsCompliant: issues.length === 0,
      issues,
      recommendations,
    };
  }

  private generateId(): string {
    return crypto.randomUUID();
  }

  /**
   * Typed event emitter methods
   */
  on<K extends keyof ProvenanceTrackerEvents>(
    event: K,
    listener: ProvenanceTrackerEvents[K]
  ): this {
    return super.on(event, listener);
  }

  emit<K extends keyof ProvenanceTrackerEvents>(
    event: K,
    ...args: Parameters<ProvenanceTrackerEvents[K]>
  ): boolean {
    return super.emit(event, ...args);
  }
}

/**
 * File-based provenance storage implementation
 */
class FileBasedStorage implements ProvenanceStorage {
  private basePath: string;

  constructor(basePath: string) {
    this.basePath = basePath;
  }

  async storeEntry(entry: ProvenanceEntry): Promise<void> {
    await this.ensureDirectory();
    const filePath = path.join(this.basePath, "entries", `${entry.id}.json`);
    await fs.writeFile(filePath, JSON.stringify(entry, null, 2));
  }

  async getEntry(id: string): Promise<ProvenanceEntry | null> {
    try {
      const filePath = path.join(this.basePath, "entries", `${id}.json`);
      const content = await fs.readFile(filePath, "utf-8");
      return JSON.parse(content);
    } catch {
      return null;
    }
  }

  async getEntriesForSpec(specId: string): Promise<ProvenanceEntry[]> {
    try {
      const entriesDir = path.join(this.basePath, "entries");
      const files = await fs.readdir(entriesDir);
      const entries: ProvenanceEntry[] = [];

      for (const file of files) {
        if (file.endsWith(".json")) {
          const entry = await this.getEntry(file.replace(".json", ""));
          if (entry && entry.specId === specId) {
            entries.push(entry);
          }
        }
      }

      return entries.sort(
        (a, b) =>
          new Date(a.timestamp).getTime() - new Date(b.timestamp).getTime()
      );
    } catch {
      return [];
    }
  }

  async updateEntry(
    id: string,
    updates: Partial<ProvenanceEntry>
  ): Promise<void> {
    const entry = await this.getEntry(id);
    if (entry) {
      Object.assign(entry, updates);
      await this.storeEntry(entry);
    }
  }

  async deleteEntry(id: string): Promise<void> {
    try {
      const filePath = path.join(this.basePath, "entries", `${id}.json`);
      await fs.unlink(filePath);
    } catch {
      // Ignore if file doesn't exist
    }
  }

  async getProvenanceChain(specId: string): Promise<ProvenanceChain | null> {
    try {
      const chainPath = path.join(this.basePath, "chains", `${specId}.json`);
      const content = await fs.readFile(chainPath, "utf-8");
      const chain = JSON.parse(content);

      // Ensure integrity property exists (for chains stored before this property was added)
      if (!chain.integrity) {
        chain.integrity = {
          verified: true,
          lastVerified: new Date().toISOString(),
          hash: "",
        };
      }

      // Ensure statistics property exists (for chains stored before this property was added)
      if (!chain.statistics) {
        chain.statistics = {
          totalEntries: chain.entries?.length || 0,
          aiAssistedEntries: 0,
          humanEntries: 0,
          aiToolsUsed: [],
          timeSpan: {
            start: new Date().toISOString(),
            end: new Date().toISOString(),
            durationMs: 0,
          },
          qualityTrends: {
            testCoverage: [],
            lintErrors: [],
            budgetUsage: [],
          },
        };
      }

      return chain;
    } catch {
      return null;
    }
  }

  async storeProvenanceChain(chain: ProvenanceChain): Promise<void> {
    await this.ensureDirectory();
    const chainPath = path.join(this.basePath, "chains", `${chain.id}.json`);
    await fs.writeFile(chainPath, JSON.stringify(chain, null, 2));
  }

  async storeAttribution(attribution: AIAttribution): Promise<void> {
    await this.ensureDirectory();
    const filePath = path.join(
      this.basePath,
      "attributions",
      `${attribution.id}.json`
    );
    await fs.writeFile(filePath, JSON.stringify(attribution, null, 2));
  }

  async getAttributions(
    startDate: string,
    endDate: string,
    toolType?: AIToolType
  ): Promise<AIAttribution[]> {
    try {
      const attributionsDir = path.join(this.basePath, "attributions");
      const files = await fs.readdir(attributionsDir);
      const attributions: AIAttribution[] = [];

      for (const file of files) {
        if (file.endsWith(".json")) {
          const content = await fs.readFile(
            path.join(attributionsDir, file),
            "utf-8"
          );
          const attribution: AIAttribution = JSON.parse(content);

          const inDateRange =
            attribution.timestamp >= startDate &&
            attribution.timestamp <= endDate;
          const matchesToolType =
            !toolType || attribution.toolType === toolType;

          if (inDateRange && matchesToolType) {
            attributions.push(attribution);
          }
        }
      }

      return attributions;
    } catch {
      return [];
    }
  }

  async verifyIntegrity(): Promise<{ verified: boolean; issues?: string[] }> {
    // Basic integrity check - ensure files exist and are readable
    try {
      await fs.access(this.basePath);
      return { verified: true };
    } catch {
      return { verified: false, issues: ["Storage directory not accessible"] };
    }
  }

  private async ensureDirectory(): Promise<void> {
    await fs.mkdir(path.join(this.basePath, "entries"), { recursive: true });
    await fs.mkdir(path.join(this.basePath, "attributions"), {
      recursive: true,
    });
    await fs.mkdir(path.join(this.basePath, "chains"), { recursive: true });
  }

  async cleanup(
    retentionDays: number
  ): Promise<{ entriesRemoved: number; attributionsRemoved: number }> {
    let entriesRemoved = 0;
    let attributionsRemoved = 0;

    try {
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - retentionDays);

      // Clean up old entries
      const entriesDir = path.join(this.basePath, "entries");
      try {
        const files = await fs.readdir(entriesDir);
        for (const file of files) {
          if (file.endsWith(".json")) {
            const filePath = path.join(entriesDir, file);
            const stats = await fs.stat(filePath);
            if (stats.mtime < cutoffDate) {
              await fs.unlink(filePath);
              entriesRemoved++;
            }
          }
        }
      } catch (error) {
        // Directory might not exist yet, continue
        console.warn("Entries directory not found during cleanup:", error);
      }

      // Clean up old attributions
      const attributionsDir = path.join(this.basePath, "attributions");
      try {
        const files = await fs.readdir(attributionsDir);
        for (const file of files) {
          if (file.endsWith(".json")) {
            const filePath = path.join(attributionsDir, file);
            const stats = await fs.stat(filePath);
            if (stats.mtime < cutoffDate) {
              await fs.unlink(filePath);
              attributionsRemoved++;
            }
          }
        }
      } catch (error) {
        // Directory might not exist yet, continue
        console.warn("Attributions directory not found during cleanup:", error);
      }

      // Clean up old chains (keep only recent ones)
      const chainsDir = path.join(this.basePath, "chains");
      try {
        const files = await fs.readdir(chainsDir);
        // Sort by modification time, keep only the 10 most recent
        const fileStats = await Promise.all(
          files
            .filter((file) => file.endsWith(".json"))
            .map(async (file) => {
              const filePath = path.join(chainsDir, file);
              const stats = await fs.stat(filePath);
              return { file, filePath, mtime: stats.mtime };
            })
        );

        fileStats.sort((a, b) => b.mtime.getTime() - a.mtime.getTime());

        // Remove old chains beyond the first 10
        for (let i = 10; i < fileStats.length; i++) {
          await fs.unlink(fileStats[i].filePath);
          // Count entries removed from chains (approximate)
          entriesRemoved += 10; // Rough estimate per chain
        }
      } catch (error) {
        // Directory might not exist yet, continue
        console.warn("Chains directory not found during cleanup:", error);
      }

      console.log(
        `Provenance cleanup completed: ${entriesRemoved} entries, ${attributionsRemoved} attributions removed`
      );
    } catch (error) {
      console.error("Error during provenance cleanup:", error);
      throw new Error(
        `Provenance cleanup failed: ${
          error instanceof Error ? error.message : "Unknown error"
        }`
      );
    }

    return { entriesRemoved, attributionsRemoved };
  }
}
