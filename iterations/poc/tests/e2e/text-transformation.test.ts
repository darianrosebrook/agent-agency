/**
 * Text Transformation E2E Test
 *
 * @author @darianrosebrook
 * @description End-to-end test for text transformation with agent evaluation and critique
 */

import { afterAll, beforeAll, describe, expect, it } from "@jest/globals";
import fs from "fs";
import path from "path";
import { TEXT_TRANSFORMATION_CRITERIA } from "./evaluation-framework";
import { E2EEvaluationRunner, E2ETestResult } from "./evaluation-runner";

describe("Text Transformation E2E", () => {
  let runner: E2EEvaluationRunner;

  beforeAll(async () => {
    runner = new E2EEvaluationRunner(true); // Mock mode for testing multi-turn feedback
    await runner.initialize();
  }, 180000); // 3 minute timeout for setup

  afterAll(async () => {
    await runner.shutdown();
  }, 30000);

  it("should complete text transformation workflow with evaluation", async () => {
    // TODO: Implement comprehensive end-to-end testing with proper performance baselines
    // - Establish realistic performance expectations for text transformation workflows
    // - Implement adaptive test timeouts based on system performance and load
    // - Add performance regression detection and alerting
    // - Support parallel test execution for faster feedback
    // - Implement test result caching for unchanged scenarios
    // - Add test flakiness detection and stabilization strategies
    // - Support different test environments (development, staging, production)
    // - Implement comprehensive test metrics and reporting
    jest.setTimeout(30000); // Current simplified timeout for basic test completion
    // Define a simpler test scenario that should pass quickly
    const scenario = {
      id: "text-transformation-e2e",
      name: "Text Transformation E2E",
      description:
        "Transform casual text into professional language and evaluate the result",
      input: {
        text: "Hey team, this is a really casual message that needs to be made more professional.",
        bannedPhrases: ["hey team"], // Only one banned phrase to make it simpler
        requiredElements: ["professional"], // Only one required element
      },
      expectedCriteria: [
        TEXT_TRANSFORMATION_CRITERIA.find((c) => c.id === "formal-language")!,
        TEXT_TRANSFORMATION_CRITERIA.find((c) => c.id === "no-banned-phrases")!,
      ].filter(Boolean), // Only test 2 key criteria
      timeout: 30000, // 30 seconds timeout
      maxIterations: 1, // Only 1 iteration to keep it simple
    };

    // Run the scenario
    const result: E2ETestResult = await runner.runScenario(scenario);

    // Debug logging
    console.log("Result structure:", {
      hasScenario: !!result.scenario,
      scenarioId: result.scenario?.id,
      outputType: typeof result.output,
      outputLength:
        typeof result.output === "string" ? result.output.length : "N/A",
      executionTime: result.executionTime,
      interactionsCount: result.agentInteractions?.length || 0,
      iterations: result.iterations,
      feedbackHistoryCount: result.feedbackHistory?.length || 0,
    });

    // Verify the result structure
    expect(result).toBeDefined();
    expect(result.scenario.id).toBe(scenario.id);
    expect(result.output).toBeDefined();
    expect(typeof result.output).toBe("string");
    expect(result.output.length).toBeGreaterThan(0);
    expect(result.executionTime).toBeGreaterThanOrEqual(0);
    expect(result.agentInteractions).toBeDefined();
    expect(result.agentInteractions.length).toBeGreaterThan(0);

    // Verify multi-turn feedback functionality
    expect(result.iterations).toBeDefined();
    expect(result.iterations).toBeGreaterThan(0);
    expect(result.feedbackHistory).toBeDefined();
    if (result.iterations && result.iterations > 1) {
      expect(result.feedbackHistory!.length).toBeGreaterThan(0);
      console.log(
        "âœ… Multi-turn feedback worked! Iterations:",
        result.iterations
      );
      console.log("ðŸ“ Feedback history:", result.feedbackHistory);
    }

    // Check that agent made tool calls
    const toolCalls = result.agentInteractions.filter(
      (i) => i.type === "tool_call"
    );
    expect(toolCalls.length).toBeGreaterThan(0);

    // Verify evaluation was performed
    expect(result.report).toBeDefined();
    expect(result.report.taskId).toBe(scenario.id);
    expect(result.report.criteria).toBeDefined();
    expect(result.report.criteria.length).toBe(
      scenario.expectedCriteria.length
    );
    expect(typeof result.report.overallScore).toBe("number");
    expect(result.report.overallScore).toBeGreaterThanOrEqual(0);
    expect(result.report.overallScore).toBeLessThanOrEqual(1);

    // Log detailed results
    console.log("\nðŸ“Š Text Transformation Results:");
    console.log(`âœ… Success: ${result.success}`);
    console.log(`ðŸ“ˆ Score: ${(result.report.overallScore * 100).toFixed(1)}%`);
    console.log(`â±ï¸  Duration: ${result.executionTime}ms`);
    console.log(`ðŸ’¬ Interactions: ${result.agentInteractions.length}`);

    console.log("\nðŸ” Detailed Criteria:");
    result.report.criteria.forEach((criterion) => {
      const status = criterion.result.passed ? "âœ…" : "âŒ";
      console.log(
        `${status} ${criterion.criteria.name}: ${(
          criterion.result.score * 100
        ).toFixed(1)}%`
      );
      if (!criterion.result.passed) {
        console.log(`   ðŸ’¡ ${criterion.result.message}`);
      }
    });

    // The test should pass (though the agent output might not be perfect)
    // We mainly want to verify the framework works
    expect(result.report.criteria.length).toBeGreaterThan(0);
    expect(result.agentInteractions.some((i) => i.type === "tool_call")).toBe(
      true
    );
  }, 120000); // 2 minutes for AI processing

  it("should evaluate text transformation criteria correctly", async () => {
    // Test specific evaluation criteria with known inputs using direct criteria evaluation
    const _evaluator = runner["evaluator"]; // Access private evaluator for testing

    // Test formal language criterion
    const formalLanguageCriteria = TEXT_TRANSFORMATION_CRITERIA.find(
      (c) => c.id === "formal-language"
    )!;
    const formalText =
      "The team requires a more professional approach to stakeholder communications.";
    const result1 = await formalLanguageCriteria.evaluate(formalText, {
      bannedPhrases: ["hey team"],
      requiredElements: ["professional"],
    });

    expect(result1.passed).toBe(true);
    expect(result1.score).toBe(1);

    // Test banned phrases criterion
    const bannedPhrasesCriteria = TEXT_TRANSFORMATION_CRITERIA.find(
      (c) => c.id === "no-banned-phrases"
    )!;
    const bannedText = "Hey team, this is a casual message.";
    const result2 = await bannedPhrasesCriteria.evaluate(bannedText, {
      bannedPhrases: ["hey team"],
    });

    expect(result2.passed).toBe(false);
    expect(result2.score).toBeLessThan(1);

    console.log("âœ… Text evaluation criteria working correctly");
  });

  it("should handle evaluation framework components", async () => {
    // Test the evaluation framework components
    const evalTypes = path.join(__dirname, "../../src/evaluation/types.ts");
    const evalOrchestrator = path.join(
      __dirname,
      "../../src/evaluation/orchestrator.ts"
    );
    const evalRunner = path.join(__dirname, "evaluation-runner.ts");
    const evalFramework = path.join(__dirname, "evaluation-framework.ts");

    expect(fs.existsSync(evalTypes)).toBe(true);
    expect(fs.existsSync(evalOrchestrator)).toBe(true);
    expect(fs.existsSync(evalRunner)).toBe(true);
    expect(fs.existsSync(evalFramework)).toBe(true);

    console.log("âœ… All evaluation framework files exist");
  });

  it("should have MCP server with AI tools available", async () => {
    // Verify MCP server tools are available
    const tools = await runner.getAvailableTools();

    expect(tools).toBeDefined();
    expect(Array.isArray(tools)).toBe(true);
    expect(tools.length).toBeGreaterThan(0);

    // Should have AI-related tools
    const aiTools = tools.filter(
      (tool: any) =>
        tool.name?.includes("ai") || tool.name?.includes("generate")
    );
    expect(aiTools.length).toBeGreaterThan(0);

    console.log(
      `âœ… MCP server ready with ${tools.length} tools (${aiTools.length} AI tools)`
    );

    // Log available tools
    console.log("\nðŸ”§ Available Tools:");
    tools.forEach((tool: any) => {
      console.log(
        `   - ${tool.name}: ${tool.description?.substring(0, 50)}...`
      );
    });
  });

  it("should handle agent interaction tracking", async () => {
    // Use the same runner instance to check interactions from the first test
    // The runner maintains state between tests in the same describe block

    // Verify that some interactions were tracked during the test suite
    // (This test runs after the first one, so interactions should exist)
    expect(runner["interactions"]).toBeDefined();

    // Since we're in mock mode and the runner is shared, interactions should be tracked
    // Let's create a fresh scenario to ensure we have interactions
    const scenario = {
      id: "text-interaction-tracking-test",
      name: "Interaction Tracking Test",
      description: "Test that agent interactions are properly tracked",
      input: {
        text: "This is a test message for interaction tracking.",
        bannedPhrases: [],
        requiredElements: ["test"],
      },
      expectedCriteria: [
        TEXT_TRANSFORMATION_CRITERIA.find((c) => c.id === "formal-language")!,
      ],
      timeout: 15000,
    };

    const result = await runner.runScenario(scenario);

    // Verify interactions were tracked for this specific run
    expect(result.agentInteractions).toBeDefined();
    expect(result.agentInteractions.length).toBeGreaterThan(0);

    // Should have tool call and evaluation interactions
    const toolCalls = result.agentInteractions.filter(
      (i) => i.type === "tool_call"
    );
    const evaluations = result.agentInteractions.filter(
      (i) => i.type === "evaluation"
    );

    expect(toolCalls.length).toBeGreaterThan(0);
    expect(evaluations.length).toBeGreaterThan(0);

    // Verify interaction structure
    result.agentInteractions.forEach((interaction) => {
      expect(interaction.timestamp).toBeDefined();
      expect(interaction.type).toBeDefined();
      expect(interaction.details).toBeDefined();
    });

    console.log("âœ… Agent interaction tracking working correctly");
  });
});
